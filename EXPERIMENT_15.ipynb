{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EXPERIMENT_17ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bo82cFfS-XUl"
      },
      "outputs": [],
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerRunner\n",
        "# text cleaning\n",
        "import re\n",
        "# Reactor restart\n",
        "from crochet import setup, wait_for\n",
        "setup()\n",
        "\n",
        "class QuotesToCsv(scrapy.Spider):\n",
        "    name = \"MJKQuotesToCsv\"\n",
        "    start_urls = [\n",
        "        'https://en.wikiquote.org/wiki/Maynard_James_Keenan',\n",
        "    ]\n",
        "    custom_settings = {\n",
        "        'ITEM_PIPELINES': {\n",
        "            '__main__.ExtractFirstLine': 1\n",
        "        },\n",
        "        'FEEDS': {\n",
        "            'quotes.csv': {\n",
        "                'format': 'csv',\n",
        "                'overwrite': True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def parse(self, response):\n",
        "        \"\"\"parse data from urls\"\"\"\n",
        "        for quote in response.css('div.mw-parser-output > ul > li'):\n",
        "            yield {'quote': quote.extract()}\n",
        "\n",
        "\n",
        "class ExtractFirstLine(object):\n",
        "    def process_item(self, item, spider):\n",
        "        \"\"\"text processing\"\"\"\n",
        "        lines = dict(item)[\"quote\"].splitlines()\n",
        "        first_line = self.__remove_html_tags__(lines[0])\n",
        "\n",
        "        return {'quote': first_line}\n",
        "\n",
        "    def __remove_html_tags__(self, text):\n",
        "        \"\"\"remove html tags from string\"\"\"\n",
        "        html_tags = re.compile('<.*?>')\n",
        "        return re.sub(html_tags, '', text)\n",
        "\n",
        "@wait_for(10)\n",
        "def run_spider():\n",
        "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
        "    crawler = CrawlerRunner()\n",
        "    d = crawler.crawl(QuotesToCsv)\n",
        "    print(\"Scraped sucessfully\")\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_spider()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL6fUKbrAmn1",
        "outputId": "4cad82fa-9653-4ba5-da17-053edb8caa02"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped sucessfully\n"
          ]
        }
      ]
    }
  ]
}